{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the columns RowNumber, CustomerId and Surname as they don't play any role in predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe.drop(columns = [\"RowNumber\", \"CustomerId\", \"Surname\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating the Value we want to predict\n",
    "- Setting all the other attributes a X Input\n",
    "- Exited a Y because we wan't to predict if a customer will exit in the coming days or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "- The data categorical value are no good to machine so we label it a numbers\n",
    "- But giving them numbers makes some high priority and other low without any reason\n",
    "- So we one hot encode them creating seperating columns\n",
    "- like gender_male a column and gender_female another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0               1        101348.88       1                 1   \n",
       "1               1        112542.58       0                 0   \n",
       "2               0        113931.57       1                 1   \n",
       "3               0         93826.63       0                 1   \n",
       "4               1         79084.10       0                 0   \n",
       "\n",
       "   Geography_Germany  Geography_Spain  Gender_Female  Gender_Male  \n",
       "0                  0                0              1            0  \n",
       "1                  0                1              1            0  \n",
       "2                  0                0              1            0  \n",
       "3                  0                0              1            0  \n",
       "4                  0                1              1            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_X = df[df.columns.difference(['Exited'])]\n",
    "df_Y = df[\"Exited\"]\n",
    "dummies = pd.get_dummies(df_X[['Geography', 'Gender']])\n",
    "df_X = df.drop(columns = ['Geography', 'Gender'])\n",
    "df_X = pd.concat([df_X, dummies], axis = 1)\n",
    "display(df_X.head())\n",
    "display(df_Y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaling then so that all the attributes will have equal weights at input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_X = scaler.fit_transform(df_X)\n",
    "df_X = pd.DataFrame(df_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting them to Train and Test data\n",
    "- Test data is never shown to model except at last so that the real accuracy can be measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df_X, df_Y, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(output_dim = 6, init = \"uniform\", activation = 'relu', input_dim = 14))\n",
    "classifier.add(Dropout(rate = 0.5))\n",
    "classifier.add(Dense(output_dim = 6, init = \"uniform\", activation = \"relu\"))\n",
    "classifier.add(Dropout(rate = 0.5))\n",
    "classifier.add(Dense(output_dim = 1, init = \"uniform\", activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the network with optimizers and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = keras.optimizers.Adam(lr = 0.001), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model with back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(x = X_train, y = Y_train, epochs = 5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(actual, pred, msg):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    cm = confusion_matrix(actual, pred)\n",
    "\n",
    "    plt.figure()\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels') \n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(['active', 'terminated']) \n",
    "    ax.yaxis.set_ticklabels(['active', 'terminated'])   \n",
    "    plt.show()       \n",
    "    sensitivity = cm[1][1]/(cm[1][0] + cm[1][1])\n",
    "    specifity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "    accuracy = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "    \n",
    "    print(msg, '\\n')\n",
    "    print('accuracy:    ', round(accuracy,2), \n",
    "      '\\nsensitivity: ', round(sensitivity,2), \n",
    "      '\\nspecifity:   ', round(specifity,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On test data \n",
      "\n",
      "accuracy:     1.0 \n",
      "sensitivity:  1.0 \n",
      "specifity:    1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict_classes(X_test)\n",
    "classification_metrics(actual = Y_test, pred = y_pred, msg = \"On test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 359us/step - loss: 0.3709 - acc: 0.8656\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 192us/step - loss: 0.1570 - acc: 0.9449\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 187us/step - loss: 0.1377 - acc: 0.9515\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 193us/step - loss: 0.1335 - acc: 0.9564\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 198us/step - loss: 0.1285 - acc: 0.9547\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 211us/step - loss: 0.1306 - acc: 0.9528\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 259us/step - loss: 0.1339 - acc: 0.9471\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 231us/step - loss: 0.1311 - acc: 0.9525\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 235us/step - loss: 0.1281 - acc: 0.9515\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 235us/step - loss: 0.1264 - acc: 0.9543\n",
      "800/800 [==============================] - 0s 350us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 393us/step - loss: 0.4064 - acc: 0.8725\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 237us/step - loss: 0.2127 - acc: 0.9143\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 190us/step - loss: 0.1974 - acc: 0.9146\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 198us/step - loss: 0.1891 - acc: 0.9094\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 213us/step - loss: 0.1924 - acc: 0.9071\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.1837 - acc: 0.9111\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 187us/step - loss: 0.1967 - acc: 0.9012\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 292us/step - loss: 0.1896 - acc: 0.9076\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 223us/step - loss: 0.1915 - acc: 0.9032\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 196us/step - loss: 0.1837 - acc: 0.9114\n",
      "800/800 [==============================] - 0s 382us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 374us/step - loss: 0.4089 - acc: 0.7979\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 201us/step - loss: 0.2393 - acc: 0.8072\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.2209 - acc: 0.8818\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 199us/step - loss: 0.2108 - acc: 0.8865\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 218us/step - loss: 0.2121 - acc: 0.8824\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - ETA: 0s - loss: 0.2129 - acc: 0.881 - 1s 186us/step - loss: 0.2119 - acc: 0.8815\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.2118 - acc: 0.8812\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 185us/step - loss: 0.2135 - acc: 0.8793\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 185us/step - loss: 0.2072 - acc: 0.8856\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 238us/step - loss: 0.2131 - acc: 0.8796\n",
      "800/800 [==============================] - 0s 375us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 509us/step - loss: 0.4008 - acc: 0.8278\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 207us/step - loss: 0.2034 - acc: 0.8804\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 217us/step - loss: 0.1866 - acc: 0.8844\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 202us/step - loss: 0.1808 - acc: 0.8837\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 183us/step - loss: 0.1765 - acc: 0.8894\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 185us/step - loss: 0.1719 - acc: 0.8892\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2s 256us/step - loss: 0.1804 - acc: 0.8822\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 187us/step - loss: 0.1755 - acc: 0.8919\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 186us/step - loss: 0.1726 - acc: 0.8889\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 192us/step - loss: 0.1778 - acc: 0.8840\n",
      "800/800 [==============================] - 0s 475us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 404us/step - loss: 0.4553 - acc: 0.7978\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 223us/step - loss: 0.3154 - acc: 0.7976\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 231us/step - loss: 0.3065 - acc: 0.7976\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 214us/step - loss: 0.3004 - acc: 0.7976\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 194us/step - loss: 0.3000 - acc: 0.7976\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 236us/step - loss: 0.2985 - acc: 0.7976\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.2980 - acc: 0.7976\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 214us/step - loss: 0.3038 - acc: 0.7976\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 212us/step - loss: 0.2924 - acc: 0.7976\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 199us/step - loss: 0.2957 - acc: 0.7976\n",
      "800/800 [==============================] - 0s 535us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 523us/step - loss: 0.3860 - acc: 0.8337\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 202us/step - loss: 0.1924 - acc: 0.8868\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2s 212us/step - loss: 0.1857 - acc: 0.8837\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2s 217us/step - loss: 0.1777 - acc: 0.8912\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2s 287us/step - loss: 0.1760 - acc: 0.8894\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2s 223us/step - loss: 0.1776 - acc: 0.8879\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 188us/step - loss: 0.1838 - acc: 0.8810\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 198us/step - loss: 0.1769 - acc: 0.8879\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 197us/step - loss: 0.1750 - acc: 0.8897\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 196us/step - loss: 0.1755 - acc: 0.8867\n",
      "800/800 [==============================] - 0s 446us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 519us/step - loss: 0.4074 - acc: 0.8737\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 196us/step - loss: 0.2255 - acc: 0.9047\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 198us/step - loss: 0.2061 - acc: 0.9076\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 197us/step - loss: 0.1882 - acc: 0.9108\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 198us/step - loss: 0.1895 - acc: 0.9072\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 197us/step - loss: 0.1923 - acc: 0.9069\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 198us/step - loss: 0.1862 - acc: 0.9049\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.1920 - acc: 0.9032\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 199us/step - loss: 0.1886 - acc: 0.9092\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 191us/step - loss: 0.1877 - acc: 0.9082\n",
      "800/800 [==============================] - 0s 575us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 530us/step - loss: 0.3795 - acc: 0.7953\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2s 226us/step - loss: 0.1738 - acc: 0.9237\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 194us/step - loss: 0.1440 - acc: 0.9590\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 199us/step - loss: 0.1218 - acc: 0.9642\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 201us/step - loss: 0.1183 - acc: 0.9594\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 199us/step - loss: 0.1137 - acc: 0.9596\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.1034 - acc: 0.9647\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 203us/step - loss: 0.1095 - acc: 0.9601\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 198us/step - loss: 0.1048 - acc: 0.9626\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 202us/step - loss: 0.1062 - acc: 0.9617\n",
      "800/800 [==============================] - 1s 641us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 3s 431us/step - loss: 0.3787 - acc: 0.8562\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 201us/step - loss: 0.1733 - acc: 0.9249\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 202us/step - loss: 0.1605 - acc: 0.9256\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 202us/step - loss: 0.1607 - acc: 0.9232\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 200us/step - loss: 0.1543 - acc: 0.9287\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 201us/step - loss: 0.1565 - acc: 0.9262\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 201us/step - loss: 0.1525 - acc: 0.9275\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2s 212us/step - loss: 0.1541 - acc: 0.9262\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2s 230us/step - loss: 0.1490 - acc: 0.9336\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2s 216us/step - loss: 0.1647 - acc: 0.9185\n",
      "800/800 [==============================] - 1s 644us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 4s 523us/step - loss: 0.3671 - acc: 0.8699\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 1s 202us/step - loss: 0.1751 - acc: 0.9061\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 1s 207us/step - loss: 0.1616 - acc: 0.9106\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 1s 203us/step - loss: 0.1618 - acc: 0.9092\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 1s 203us/step - loss: 0.1322 - acc: 0.9375\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 1s 203us/step - loss: 0.1247 - acc: 0.9317\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 1s 204us/step - loss: 0.1387 - acc: 0.9235\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 1s 205us/step - loss: 0.1293 - acc: 0.9290\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 1s 204us/step - loss: 0.1261 - acc: 0.9324\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 1s 205us/step - loss: 0.1261 - acc: 0.9301\n",
      "800/800 [==============================] - 1s 960us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9788749999552966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 6, init = \"uniform\", activation = 'relu', input_dim = 14))\n",
    "    classifier.add(Dropout(rate = 0.5))\n",
    "    classifier.add(Dense(output_dim = 6, init = \"uniform\", activation = \"relu\"))\n",
    "    classifier.add(Dropout(rate = 0.5))\n",
    "    classifier.add(Dense(output_dim = 1, init = \"uniform\", activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer = keras.optimizers.Adam(lr = 0.001), loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 10)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = Y_train, cv = 10)\n",
    "\n",
    "display(accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9788749999552966"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 334us/step - loss: 0.5113 - acc: 0.7958\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.2485 - acc: 0.7960\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1917 - acc: 0.8717\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1722 - acc: 0.9522\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1594 - acc: 0.9518\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1493 - acc: 0.9519\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1414 - acc: 0.9524\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1336 - acc: 0.9543\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1329 - acc: 0.9515\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1285 - acc: 0.9526\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1280 - acc: 0.9514\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1186 - acc: 0.9571\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1233 - acc: 0.9529\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1319 - acc: 0.9468\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1175 - acc: 0.9561\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1257 - acc: 0.9506\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1215 - acc: 0.9531\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1154 - acc: 0.9568\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1208 - acc: 0.9533\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1108 - acc: 0.9593\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1257 - acc: 0.9503\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1227 - acc: 0.9521\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1187 - acc: 0.9544\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1217 - acc: 0.9526\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1210 - acc: 0.9531\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1279 - acc: 0.9489\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.1208 - acc: 0.9532\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1222 - acc: 0.9524\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1233 - acc: 0.9517\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.1242 - acc: 0.9511\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 109us/step - loss: 0.1217 - acc: 0.9526\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.1263 - acc: 0.9499\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1249 - acc: 0.9507\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1192 - acc: 0.9542\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1242 - acc: 0.9511\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1247 - acc: 0.9508\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1203 - acc: 0.9535\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1290 - acc: 0.9482\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1205 - acc: 0.9533\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1201 - acc: 0.9536\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1258 - acc: 0.9501\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1272 - acc: 0.9493\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1242 - acc: 0.9511\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1269 - acc: 0.9494\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1242 - acc: 0.9511\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1219 - acc: 0.9525\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1212 - acc: 0.9529\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1226 - acc: 0.9521\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1260 - acc: 0.9500\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1237 - acc: 0.9514\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1247 - acc: 0.9508\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1249 - acc: 0.9507\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1194 - acc: 0.9540\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1258 - acc: 0.9501\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1235 - acc: 0.9515\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1196 - acc: 0.9539\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1217 - acc: 0.9526\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1288 - acc: 0.9483\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1240 - acc: 0.9512\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.1212 - acc: 0.9529\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1237 - acc: 0.9514\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1150 - acc: 0.9567\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.1228 - acc: 0.9519\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1233 - acc: 0.9517\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.1189 - acc: 0.9543\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1238 - acc: 0.9514\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1267 - acc: 0.9496\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1210 - acc: 0.9531\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.1237 - acc: 0.9514\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.1276 - acc: 0.9490\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.1171 - acc: 0.9554\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1198 - acc: 0.9537\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1214 - acc: 0.9528\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1242 - acc: 0.9511\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1247 - acc: 0.9508\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1226 - acc: 0.9521\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1175 - acc: 0.9551\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1180 - acc: 0.9549\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1156 - acc: 0.9562\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1259 - acc: 0.9501\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1214 - acc: 0.9528\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1226 - acc: 0.9521\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1212 - acc: 0.9529\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1270 - acc: 0.9494\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.1240 - acc: 0.9512\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1187 - acc: 0.9544\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1270 - acc: 0.9494\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1198 - acc: 0.9537\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1156 - acc: 0.9562\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1210 - acc: 0.9531\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1193 - acc: 0.9540\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1212 - acc: 0.9529\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.1165 - acc: 0.9557\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1167 - acc: 0.9556\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1308 - acc: 0.9472\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1198 - acc: 0.9537\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1242 - acc: 0.9511\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1212 - acc: 0.9529\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1212 - acc: 0.9529\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1254 - acc: 0.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 3s 366us/step - loss: 0.5825 - acc: 0.8826\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.3167 - acc: 0.9626\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.2454 - acc: 0.9662\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.2219 - acc: 0.9642\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.2028 - acc: 0.9629\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1824 - acc: 0.9654\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.1824 - acc: 0.9586\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.1706 - acc: 0.9600\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 112us/step - loss: 0.1555 - acc: 0.9643\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 113us/step - loss: 0.1439 - acc: 0.9662\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.1444 - acc: 0.9626\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 116us/step - loss: 0.1426 - acc: 0.9615\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1453 - acc: 0.9582\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.1358 - acc: 0.9614\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 112us/step - loss: 0.1273 - acc: 0.9646\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 122us/step - loss: 0.1195 - acc: 0.9676\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 112us/step - loss: 0.1323 - acc: 0.9608\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1304 - acc: 0.9619\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.1247 - acc: 0.9633\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1229 - acc: 0.9637\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1180 - acc: 0.9664\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1309 - acc: 0.9600\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1294 - acc: 0.9606\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1245 - acc: 0.9622\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1168 - acc: 0.9653\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1186 - acc: 0.9649\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1244 - acc: 0.9622\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1112 - acc: 0.9681\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1270 - acc: 0.9607\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1245 - acc: 0.9625\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1256 - acc: 0.9621\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1199 - acc: 0.9639\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1186 - acc: 0.9649\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1196 - acc: 0.9635\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1135 - acc: 0.9660\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1229 - acc: 0.9632\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1248 - acc: 0.9622\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1240 - acc: 0.9621\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1307 - acc: 0.9608\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1233 - acc: 0.9632\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1183 - acc: 0.9642\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 110us/step - loss: 0.1185 - acc: 0.9644\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.1269 - acc: 0.9614\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1169 - acc: 0.9656\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1208 - acc: 0.9629\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.1278 - acc: 0.9608\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.1209 - acc: 0.9633\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.1278 - acc: 0.9599\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.1198 - acc: 0.9643\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1272 - acc: 0.9607\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.1275 - acc: 0.9619\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1195 - acc: 0.9640\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.1222 - acc: 0.9628\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1203 - acc: 0.9644\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1297 - acc: 0.9607\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1218 - acc: 0.9635\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1301 - acc: 0.9603\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1268 - acc: 0.9614\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1286 - acc: 0.9610\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1196 - acc: 0.9639\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1271 - acc: 0.9614\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1183 - acc: 0.9642\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 121us/step - loss: 0.1244 - acc: 0.9622\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 102us/step - loss: 0.1161 - acc: 0.9657\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 116us/step - loss: 0.1185 - acc: 0.9650\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 114us/step - loss: 0.1239 - acc: 0.9633\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.1262 - acc: 0.9612\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1213 - acc: 0.9628\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1258 - acc: 0.9622\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1222 - acc: 0.9640\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1192 - acc: 0.9636\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1195 - acc: 0.9644\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1209 - acc: 0.9636\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1260 - acc: 0.9622\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1248 - acc: 0.9633\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1258 - acc: 0.9621\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1260 - acc: 0.9612\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1214 - acc: 0.9644\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1236 - acc: 0.9626\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1278 - acc: 0.9614\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1249 - acc: 0.9618\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.1242 - acc: 0.9632\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1246 - acc: 0.9622\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.1198 - acc: 0.9621\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1217 - acc: 0.9635\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1252 - acc: 0.9622\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1239 - acc: 0.9621\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1163 - acc: 0.9647\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1228 - acc: 0.9626\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1245 - acc: 0.9622\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1189 - acc: 0.9637\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1236 - acc: 0.9618\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1250 - acc: 0.9621\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.1204 - acc: 0.9637\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 119us/step - loss: 0.1208 - acc: 0.9639\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.1239 - acc: 0.9621\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1228 - acc: 0.9636\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1256 - acc: 0.9619\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1270 - acc: 0.9600\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1168 - acc: 0.9658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 345us/step - loss: 0.5331 - acc: 0.8228\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.2258 - acc: 0.8818\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.1623 - acc: 0.9186\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.1396 - acc: 0.9296\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 106us/step - loss: 0.1325 - acc: 0.9306\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1266 - acc: 0.9310\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.1266 - acc: 0.9290\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1252 - acc: 0.9350\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1249 - acc: 0.9324\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1272 - acc: 0.9244\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1228 - acc: 0.9301\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1240 - acc: 0.9306\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1186 - acc: 0.9317\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1280 - acc: 0.9232\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1238 - acc: 0.9271\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1289 - acc: 0.9276\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1254 - acc: 0.9290\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1238 - acc: 0.9283\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1244 - acc: 0.9287\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1210 - acc: 0.9310\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1233 - acc: 0.9281\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.1249 - acc: 0.9271\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1233 - acc: 0.9292\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1183 - acc: 0.9307\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1241 - acc: 0.9247\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1177 - acc: 0.9299\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1157 - acc: 0.9307\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.1224 - acc: 0.9297\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1201 - acc: 0.9283\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1243 - acc: 0.9242\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.1253 - acc: 0.9256\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 108us/step - loss: 0.1170 - acc: 0.9317\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.1209 - acc: 0.9276\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1194 - acc: 0.9283\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1221 - acc: 0.9261\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1196 - acc: 0.9289\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1177 - acc: 0.9278\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1130 - acc: 0.9358\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1200 - acc: 0.9285\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1170 - acc: 0.9300\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1242 - acc: 0.9240\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1267 - acc: 0.9235\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1261 - acc: 0.9221\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1220 - acc: 0.9258\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1210 - acc: 0.9260\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1172 - acc: 0.9310\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1168 - acc: 0.9333\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1173 - acc: 0.9247\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1164 - acc: 0.9310\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1255 - acc: 0.9276\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1215 - acc: 0.9250\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1238 - acc: 0.9322\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1243 - acc: 0.9283\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1203 - acc: 0.9296\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1229 - acc: 0.9310\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1214 - acc: 0.9336\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1260 - acc: 0.9290\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1217 - acc: 0.9311\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1225 - acc: 0.9297\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1229 - acc: 0.9303\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1217 - acc: 0.9276\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1265 - acc: 0.9240\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1286 - acc: 0.9242\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1164 - acc: 0.9290\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1212 - acc: 0.9268\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1196 - acc: 0.9285\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1195 - acc: 0.9304\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1206 - acc: 0.9314\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1219 - acc: 0.9289\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1314 - acc: 0.9218\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1258 - acc: 0.9267\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1151 - acc: 0.9325\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1142 - acc: 0.9301\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 2s 318us/step - loss: 0.1188 - acc: 0.9293\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 2s 298us/step - loss: 0.1196 - acc: 0.9272\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 2s 326us/step - loss: 0.1214 - acc: 0.9256\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 2s 327us/step - loss: 0.1145 - acc: 0.9318 0s - loss: 0.1139 - acc: 0\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 2s 257us/step - loss: 0.1218 - acc: 0.9290\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 179us/step - loss: 0.1255 - acc: 0.9287\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 2s 226us/step - loss: 0.1296 - acc: 0.9272\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 3s 356us/step - loss: 0.1197 - acc: 0.9287\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 2s 285us/step - loss: 0.1244 - acc: 0.9211\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 203us/step - loss: 0.1253 - acc: 0.9224\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 150us/step - loss: 0.1237 - acc: 0.9307\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 123us/step - loss: 0.1187 - acc: 0.9310\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.1158 - acc: 0.9293\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.1147 - acc: 0.9322\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1241 - acc: 0.9250\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1217 - acc: 0.9250\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1240 - acc: 0.9261\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1227 - acc: 0.9286\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1211 - acc: 0.9274\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1172 - acc: 0.9304\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1206 - acc: 0.9281\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1256 - acc: 0.9243\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 198us/step - loss: 0.1194 - acc: 0.9318\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - ETA: 0s - loss: 0.1161 - acc: 0.9287- ETA: 0s - loss: 0.1118 - ac - 3s 394us/step - loss: 0.1155 - acc: 0.9294\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 2s 288us/step - loss: 0.1301 - acc: 0.9200\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 2s 229us/step - loss: 0.1137 - acc: 0.9340\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 158us/step - loss: 0.1188 - acc: 0.9267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 3s 362us/step - loss: 0.5243 - acc: 0.8346\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.2121 - acc: 0.9274\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1604 - acc: 0.9253\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1405 - acc: 0.9317\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1362 - acc: 0.9344\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1359 - acc: 0.9314\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1411 - acc: 0.9299\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1359 - acc: 0.9293\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1401 - acc: 0.9262\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1345 - acc: 0.9278\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1340 - acc: 0.9287\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1289 - acc: 0.9349\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1349 - acc: 0.9269: 0s - loss: 0.1214 - \n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1330 - acc: 0.9310\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1382 - acc: 0.9265\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1306 - acc: 0.9294\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1370 - acc: 0.9293\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1299 - acc: 0.9300\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 134us/step - loss: 0.1395 - acc: 0.9251\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.1288 - acc: 0.9308\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 112us/step - loss: 0.1390 - acc: 0.9285\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1344 - acc: 0.9306\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1371 - acc: 0.9260\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1406 - acc: 0.9262\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1348 - acc: 0.9293\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1311 - acc: 0.9312\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1343 - acc: 0.9283\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1328 - acc: 0.9300\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1306 - acc: 0.9315\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1317 - acc: 0.9326\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1353 - acc: 0.9268\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1326 - acc: 0.9304\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1313 - acc: 0.9324: 0s - loss: 0.1306 - acc: 0.932\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1321 - acc: 0.9322\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1362 - acc: 0.9262\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1314 - acc: 0.9296\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 156us/step - loss: 0.1286 - acc: 0.9318\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 115us/step - loss: 0.1376 - acc: 0.9290\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1313 - acc: 0.9292\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1273 - acc: 0.9325\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1275 - acc: 0.9322\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1319 - acc: 0.9331\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1332 - acc: 0.9287\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1284 - acc: 0.9306\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1344 - acc: 0.9265\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1335 - acc: 0.9275\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1368 - acc: 0.9290\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1306 - acc: 0.9285\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1352 - acc: 0.9293\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1321 - acc: 0.9310\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1357 - acc: 0.9279\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1389 - acc: 0.9215\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1335 - acc: 0.9303\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1318 - acc: 0.9307\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1320 - acc: 0.9328\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1330 - acc: 0.9308\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1320 - acc: 0.9306\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1342 - acc: 0.9287\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1334 - acc: 0.9321\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1325 - acc: 0.9292\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1261 - acc: 0.9367\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1339 - acc: 0.9282\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1294 - acc: 0.9303\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.1355 - acc: 0.9293\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1414 - acc: 0.9242\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1348 - acc: 0.9304\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1304 - acc: 0.9299\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.1336 - acc: 0.9292\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1328 - acc: 0.9300\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1297 - acc: 0.9329\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1381 - acc: 0.9281\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1353 - acc: 0.9293\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1320 - acc: 0.9299\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1345 - acc: 0.9317\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1276 - acc: 0.9357\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1291 - acc: 0.9340\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1312 - acc: 0.9300\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1268 - acc: 0.9333\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1287 - acc: 0.9322\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1347 - acc: 0.9299\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1351 - acc: 0.9276\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1328 - acc: 0.9301\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1290 - acc: 0.9331\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.1367 - acc: 0.9279\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1280 - acc: 0.9358\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.1272 - acc: 0.9344\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1332 - acc: 0.9296\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.1348 - acc: 0.9282\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1347 - acc: 0.9279\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 75us/step - loss: 0.1376 - acc: 0.9272\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1315 - acc: 0.9290\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1325 - acc: 0.9306\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1283 - acc: 0.9331\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1317 - acc: 0.9278\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1384 - acc: 0.9274\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1332 - acc: 0.9322\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1369 - acc: 0.9276\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1359 - acc: 0.9281\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1292 - acc: 0.9329\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1285 - acc: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 287us/step - loss: 0.5086 - acc: 0.7975\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.2613 - acc: 0.7976\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.2017 - acc: 0.8482\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1726 - acc: 0.9537\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1568 - acc: 0.9553\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1497 - acc: 0.9512\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1471 - acc: 0.9471\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1386 - acc: 0.9500\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1321 - acc: 0.9522\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1294 - acc: 0.9519\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1318 - acc: 0.9485\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1248 - acc: 0.9528\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 113us/step - loss: 0.1280 - acc: 0.9497\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1282 - acc: 0.9492\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1232 - acc: 0.9522\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1267 - acc: 0.9497\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1228 - acc: 0.9521\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1283 - acc: 0.9485\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1359 - acc: 0.9436\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1268 - acc: 0.9494\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1214 - acc: 0.9528\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1211 - acc: 0.9529\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1248 - acc: 0.9506\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1313 - acc: 0.9465\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1246 - acc: 0.9507\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1279 - acc: 0.9486\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1306 - acc: 0.9469\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1303 - acc: 0.9471\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1232 - acc: 0.9515\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1171 - acc: 0.9553\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 111us/step - loss: 0.1252 - acc: 0.9503\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.1250 - acc: 0.9504\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.1288 - acc: 0.9481\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1218 - acc: 0.9524\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1261 - acc: 0.9497\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1243 - acc: 0.9508\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1243 - acc: 0.9508\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1260 - acc: 0.9499\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1250 - acc: 0.9504\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1232 - acc: 0.9515\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1200 - acc: 0.9535\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1151 - acc: 0.9564\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1245 - acc: 0.9507\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1199 - acc: 0.9535\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1259 - acc: 0.9499: 0s - loss: 0.1255 - acc: 0.950\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1257 - acc: 0.9500\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1229 - acc: 0.9517\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1255 - acc: 0.9501\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1172 - acc: 0.9551\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1245 - acc: 0.9507\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1252 - acc: 0.9503\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1268 - acc: 0.9493\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1225 - acc: 0.9519\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1229 - acc: 0.9517\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1216 - acc: 0.9525\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1257 - acc: 0.9500\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1234 - acc: 0.9514\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1295 - acc: 0.9476\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1281 - acc: 0.9485\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1207 - acc: 0.9531\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1156 - acc: 0.9561\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1215 - acc: 0.9525\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1275 - acc: 0.9489\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1257 - acc: 0.9500\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1272 - acc: 0.9490\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1265 - acc: 0.9494\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1223 - acc: 0.9521\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1225 - acc: 0.9519\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1234 - acc: 0.9514\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1135 - acc: 0.9574\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1250 - acc: 0.9504\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1206 - acc: 0.9531\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1234 - acc: 0.9514\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1293 - acc: 0.9478\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1247 - acc: 0.9506\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1236 - acc: 0.9512\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1245 - acc: 0.9507\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1261 - acc: 0.9497\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1250 - acc: 0.9504\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1179 - acc: 0.9547\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1236 - acc: 0.9512\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1231 - acc: 0.9515\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1241 - acc: 0.9510\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1216 - acc: 0.9525: 0s - loss: 0.1155 - acc\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1238 - acc: 0.9511\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1218 - acc: 0.9524\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1206 - acc: 0.9531\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1305 - acc: 0.9471\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1241 - acc: 0.9510\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1293 - acc: 0.9478\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1310 - acc: 0.9467\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1203 - acc: 0.9533\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1279 - acc: 0.9486\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1195 - acc: 0.9537\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1200 - acc: 0.9535\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1252 - acc: 0.9503\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1250 - acc: 0.9504\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.1220 - acc: 0.9522\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1232 - acc: 0.9515\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1297 - acc: 0.9475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 293us/step - loss: 0.5025 - acc: 0.7983\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.2525 - acc: 0.7985\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1874 - acc: 0.8782\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1666 - acc: 0.9569\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1513 - acc: 0.9586\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1387 - acc: 0.9604\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1371 - acc: 0.9543\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1240 - acc: 0.9610\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1262 - acc: 0.9554\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1221 - acc: 0.9562\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1188 - acc: 0.9572\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 76us/step - loss: 0.1154 - acc: 0.9583\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1177 - acc: 0.9560\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1155 - acc: 0.9569\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1122 - acc: 0.9587\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1158 - acc: 0.9562\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1105 - acc: 0.9593\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1152 - acc: 0.9564\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1090 - acc: 0.9600\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1100 - acc: 0.9593\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1072 - acc: 0.9608\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1168 - acc: 0.9553\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1074 - acc: 0.9607\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1054 - acc: 0.9618\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1144 - acc: 0.9567\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1058 - acc: 0.9615\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1082 - acc: 0.9601\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1149 - acc: 0.9564\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1153 - acc: 0.9561\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1080 - acc: 0.9603\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1124 - acc: 0.9578\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1092 - acc: 0.9596\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1124 - acc: 0.9578\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1175 - acc: 0.9549\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1129 - acc: 0.9575\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1146 - acc: 0.9565\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1131 - acc: 0.9574\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1206 - acc: 0.9531\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1068 - acc: 0.9610\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1102 - acc: 0.9590\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1141 - acc: 0.9568\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1153 - acc: 0.9561\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1146 - acc: 0.9565\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1087 - acc: 0.9599\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1102 - acc: 0.9590\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1146 - acc: 0.9565\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1177 - acc: 0.9547\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1162 - acc: 0.9556\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1105 - acc: 0.9589\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1148 - acc: 0.9564\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1109 - acc: 0.9586\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1167 - acc: 0.9553\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1162 - acc: 0.9556\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1169 - acc: 0.9551\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1061 - acc: 0.9614\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1021 - acc: 0.9636\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1185 - acc: 0.9543\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1170 - acc: 0.9551\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1095 - acc: 0.9594\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1133 - acc: 0.9572\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1131 - acc: 0.9574\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1095 - acc: 0.9594\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1148 - acc: 0.9564\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1162 - acc: 0.9556\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1160 - acc: 0.9557\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1073 - acc: 0.9607\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1192 - acc: 0.9539\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1158 - acc: 0.9558\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1162 - acc: 0.9556\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1165 - acc: 0.9554\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1169 - acc: 0.9551\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1131 - acc: 0.9574\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1193 - acc: 0.9537\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1124 - acc: 0.9578\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1153 - acc: 0.9561\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1184 - acc: 0.9543\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1107 - acc: 0.9587\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1126 - acc: 0.9576\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1076 - acc: 0.9606\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1194 - acc: 0.9537\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1145 - acc: 0.9565\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.1110 - acc: 0.9586\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1155 - acc: 0.9560\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1189 - acc: 0.9540\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1203 - acc: 0.9532\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1055 - acc: 0.9618\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1194 - acc: 0.9537\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1134 - acc: 0.9572\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1095 - acc: 0.9594\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1167 - acc: 0.9553\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1138 - acc: 0.9569\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1138 - acc: 0.9569\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1203 - acc: 0.9532\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1122 - acc: 0.9579\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1153 - acc: 0.9561\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1107 - acc: 0.9587\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1174 - acc: 0.9549\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1100 - acc: 0.9592\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1174 - acc: 0.9549\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.1063 - acc: 0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 299us/step - loss: 0.5573 - acc: 0.7946\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.3164 - acc: 0.7954\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.2484 - acc: 0.7954\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.2359 - acc: 0.7990\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 77us/step - loss: 0.2224 - acc: 0.8874\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.2201 - acc: 0.8836\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.2183 - acc: 0.8817\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2135 - acc: 0.8847\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2101 - acc: 0.8867\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2080 - acc: 0.8878\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2142 - acc: 0.8807\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2098 - acc: 0.8849\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.2084 - acc: 0.8860\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2126 - acc: 0.8817\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2139 - acc: 0.8803\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2159 - acc: 0.8782\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2118 - acc: 0.8822\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2130 - acc: 0.8810\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2151 - acc: 0.8789\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2151 - acc: 0.8789\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2101 - acc: 0.8839\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2109 - acc: 0.8831\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2070 - acc: 0.8869\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2072 - acc: 0.8867\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2091 - acc: 0.8847\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2124 - acc: 0.8815\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2054 - acc: 0.8883\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2056 - acc: 0.8882\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2087 - acc: 0.8851\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2103 - acc: 0.8836\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2097 - acc: 0.8842\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2073 - acc: 0.8865\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2084 - acc: 0.8854\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2095 - acc: 0.8843\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2102 - acc: 0.8836\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2101 - acc: 0.8837\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2105 - acc: 0.8833\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2098 - acc: 0.8840\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2046 - acc: 0.8892\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2121 - acc: 0.8818\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2044 - acc: 0.8893\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2068 - acc: 0.8869\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2048 - acc: 0.8889\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2084 - acc: 0.8854\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2084 - acc: 0.8854\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2137 - acc: 0.8803\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2109 - acc: 0.8829\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2068 - acc: 0.8869\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2078 - acc: 0.8860\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2118 - acc: 0.8821\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2073 - acc: 0.8865\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2051 - acc: 0.8886\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2083 - acc: 0.8856\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2124 - acc: 0.8815\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2132 - acc: 0.8807\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2020 - acc: 0.8917\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2044 - acc: 0.8893\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2085 - acc: 0.8853\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2127 - acc: 0.8812\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2080 - acc: 0.8858\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2097 - acc: 0.8842\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2118 - acc: 0.8821: 0s - loss: 0.2190 - \n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2125 - acc: 0.8814\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2091 - acc: 0.8847\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2090 - acc: 0.8849\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2108 - acc: 0.8831\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2052 - acc: 0.8886: 0s - loss: 0.2175 - \n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.2091 - acc: 0.8847\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2097 - acc: 0.8842\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2081 - acc: 0.8857\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2070 - acc: 0.8868\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2142 - acc: 0.8797\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2074 - acc: 0.8864\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2170 - acc: 0.8769\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2118 - acc: 0.8821\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2121 - acc: 0.8818\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2086 - acc: 0.8853\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2090 - acc: 0.8849\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2075 - acc: 0.8862\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2074 - acc: 0.8864\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2002 - acc: 0.8933\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2087 - acc: 0.8851\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.2121 - acc: 0.8818\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2158 - acc: 0.8782\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.2088 - acc: 0.8850\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.2053 - acc: 0.8885\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.2094 - acc: 0.8844\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.2082 - acc: 0.8856\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.2061 - acc: 0.8876\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2125 - acc: 0.8814\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.2017 - acc: 0.8919\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.2175 - acc: 0.8765\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2064 - acc: 0.8874\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.2050 - acc: 0.8887\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2091 - acc: 0.8847\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2052 - acc: 0.8885\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2108 - acc: 0.8831\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2128 - acc: 0.8811\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2101 - acc: 0.8837\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.2083 - acc: 0.8856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 306us/step - loss: 0.5928 - acc: 0.8046\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.3312 - acc: 0.8489\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2764 - acc: 0.8676\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2569 - acc: 0.8767\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2482 - acc: 0.8806\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2400 - acc: 0.8814\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2385 - acc: 0.8794\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2348 - acc: 0.8836\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2460 - acc: 0.8740\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2430 - acc: 0.8765\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2413 - acc: 0.8704\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2414 - acc: 0.8762\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2406 - acc: 0.8746\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2443 - acc: 0.8742\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2383 - acc: 0.8768\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2424 - acc: 0.8761\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2434 - acc: 0.8801\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2405 - acc: 0.8757\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2401 - acc: 0.8793\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2400 - acc: 0.8751\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2421 - acc: 0.8736\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2431 - acc: 0.8753\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2393 - acc: 0.8785\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2425 - acc: 0.8757\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2387 - acc: 0.8781\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - ETA: 0s - loss: 0.2384 - acc: 0.879 - 1s 91us/step - loss: 0.2389 - acc: 0.8787\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2407 - acc: 0.8761\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2458 - acc: 0.8756\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2364 - acc: 0.8821\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2426 - acc: 0.8758\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2455 - acc: 0.8733\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2445 - acc: 0.8729\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2413 - acc: 0.8811\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2366 - acc: 0.8796\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2422 - acc: 0.8729\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2390 - acc: 0.8758\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2402 - acc: 0.8799\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2438 - acc: 0.8735\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2438 - acc: 0.8750\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2402 - acc: 0.8764\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2441 - acc: 0.8761\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2383 - acc: 0.8778\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2449 - acc: 0.8746\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2423 - acc: 0.8728\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2339 - acc: 0.8779\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2434 - acc: 0.8753\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2383 - acc: 0.8801\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2395 - acc: 0.8754\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2418 - acc: 0.8756\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2389 - acc: 0.8801\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2428 - acc: 0.8758\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2340 - acc: 0.8818\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2370 - acc: 0.8808\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2367 - acc: 0.8806\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2371 - acc: 0.8779\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2395 - acc: 0.8781\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2360 - acc: 0.8782\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2466 - acc: 0.8683\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2410 - acc: 0.8737\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2337 - acc: 0.8861\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2362 - acc: 0.8786\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2449 - acc: 0.8729\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2401 - acc: 0.8782\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.2369 - acc: 0.8782\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2365 - acc: 0.8785\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2385 - acc: 0.8781\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2428 - acc: 0.8760\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2419 - acc: 0.8764\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2423 - acc: 0.8746\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2404 - acc: 0.8761\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2363 - acc: 0.8803\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2331 - acc: 0.8787\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2374 - acc: 0.8779\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2408 - acc: 0.8765\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2311 - acc: 0.8833\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2417 - acc: 0.8786\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2454 - acc: 0.8740\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2426 - acc: 0.8751\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2390 - acc: 0.8786\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2425 - acc: 0.8754\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2408 - acc: 0.8757\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2410 - acc: 0.8792\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2422 - acc: 0.8735\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2445 - acc: 0.8737\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2404 - acc: 0.8765\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2421 - acc: 0.8762\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2381 - acc: 0.8822\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2434 - acc: 0.8739\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.2337 - acc: 0.8822\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.2435 - acc: 0.8751\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.2369 - acc: 0.8794\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.2340 - acc: 0.8824\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.2421 - acc: 0.8761\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.2451 - acc: 0.8735\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.2382 - acc: 0.8781\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.2417 - acc: 0.8800\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2328 - acc: 0.8835\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2360 - acc: 0.8783\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.2444 - acc: 0.8733\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.2460 - acc: 0.8731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 313us/step - loss: 0.5281 - acc: 0.7982\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2319 - acc: 0.7990\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1706 - acc: 0.8950\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1498 - acc: 0.9757\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1377 - acc: 0.9726\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1245 - acc: 0.9731\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1093 - acc: 0.9778\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1010 - acc: 0.9778\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0984 - acc: 0.9749\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0953 - acc: 0.9737\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0889 - acc: 0.9757\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0878 - acc: 0.9746\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0856 - acc: 0.9746\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0845 - acc: 0.9743\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0850 - acc: 0.9733\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0863 - acc: 0.9722\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0779 - acc: 0.9764\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0829 - acc: 0.9735\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0744 - acc: 0.9776\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0759 - acc: 0.9767\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0773 - acc: 0.9758\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0803 - acc: 0.9743\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.0833 - acc: 0.9729\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0744 - acc: 0.9771\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0794 - acc: 0.9747\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0856 - acc: 0.9718\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0793 - acc: 0.9747\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0814 - acc: 0.9737\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0760 - acc: 0.9762\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0774 - acc: 0.9756\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0762 - acc: 0.9761\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0799 - acc: 0.9744\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.0792 - acc: 0.9747\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0765 - acc: 0.9760\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0783 - acc: 0.9751\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0786 - acc: 0.9750\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0777 - acc: 0.9754\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0703 - acc: 0.9787\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0731 - acc: 0.9775\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0762 - acc: 0.9761\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.0733 - acc: 0.9774\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0904 - acc: 0.9697\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.0835 - acc: 0.9728\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0756 - acc: 0.9764\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0826 - acc: 0.9732\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0774 - acc: 0.9756\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0835 - acc: 0.9728\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.0832 - acc: 0.9729\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0810 - acc: 0.9739\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0756 - acc: 0.9764\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0816 - acc: 0.9736\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.0771 - acc: 0.9757\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.0753 - acc: 0.9765\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.0829 - acc: 0.9731\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.0731 - acc: 0.9775\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0798 - acc: 0.9744\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.0780 - acc: 0.9753\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.0774 - acc: 0.9756\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0868 - acc: 0.9712\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.0765 - acc: 0.9760\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0753 - acc: 0.9765\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.0801 - acc: 0.9743\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.0734 - acc: 0.9774\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.0805 - acc: 0.9742\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.0786 - acc: 0.9750\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0826 - acc: 0.9732\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.0774 - acc: 0.9756\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0774 - acc: 0.9756\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.0792 - acc: 0.9747\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0762 - acc: 0.9761\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0718 - acc: 0.9781\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0817 - acc: 0.9736\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0832 - acc: 0.9729\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.0847 - acc: 0.9722\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0804 - acc: 0.9742\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.0841 - acc: 0.9725\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.0753 - acc: 0.9765\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.0786 - acc: 0.9750\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.0850 - acc: 0.9721\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.0720 - acc: 0.9781\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0746 - acc: 0.9768\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0740 - acc: 0.9771\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.0749 - acc: 0.9767\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.0832 - acc: 0.9729\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.0718 - acc: 0.9781\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.0758 - acc: 0.9762\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.0755 - acc: 0.9764\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0777 - acc: 0.9754\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.0780 - acc: 0.9753\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.0765 - acc: 0.9760\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.0817 - acc: 0.9736\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.0780 - acc: 0.9753\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.0823 - acc: 0.9733\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.0789 - acc: 0.9749\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.0768 - acc: 0.9758\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.0734 - acc: 0.9774\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.0789 - acc: 0.9749\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 104us/step - loss: 0.0792 - acc: 0.9747\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 115us/step - loss: 0.0802 - acc: 0.9743\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.0768 - acc: 0.9758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 321us/step - loss: 0.5686 - acc: 0.7950\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.3079 - acc: 0.7961\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2443 - acc: 0.7961\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2311 - acc: 0.8014\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2222 - acc: 0.8869\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2167 - acc: 0.8872\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2123 - acc: 0.8881\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2098 - acc: 0.8881\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2136 - acc: 0.8822\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2100 - acc: 0.8854\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2066 - acc: 0.8882\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2092 - acc: 0.8850\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2136 - acc: 0.8804\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2085 - acc: 0.8854\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2091 - acc: 0.8847\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.2096 - acc: 0.8842\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2083 - acc: 0.8854\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2031 - acc: 0.8904\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2047 - acc: 0.8889\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2093 - acc: 0.8843\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2114 - acc: 0.8822\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2056 - acc: 0.8879\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2078 - acc: 0.8857\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2057 - acc: 0.8878\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2051 - acc: 0.8883\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2184 - acc: 0.8754\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2057 - acc: 0.8878\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2053 - acc: 0.8882\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2132 - acc: 0.8804\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1997 - acc: 0.8936\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2009 - acc: 0.8924\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2104 - acc: 0.8832\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2089 - acc: 0.8846\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2061 - acc: 0.8874\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2062 - acc: 0.8872\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.2031 - acc: 0.8903\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.2026 - acc: 0.8907\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.2020 - acc: 0.8912\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2116 - acc: 0.8821\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2071 - acc: 0.8864\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2034 - acc: 0.8900\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2049 - acc: 0.8885\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2061 - acc: 0.8874\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2055 - acc: 0.8879\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2023 - acc: 0.8910\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2061 - acc: 0.8874\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2058 - acc: 0.8876\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2022 - acc: 0.8911\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2055 - acc: 0.8879\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2166 - acc: 0.8772\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.2111 - acc: 0.8825\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2061 - acc: 0.8874\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2084 - acc: 0.8851\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2067 - acc: 0.8868\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2061 - acc: 0.8874\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.2092 - acc: 0.8843\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2051 - acc: 0.8883\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1992 - acc: 0.8940\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2057 - acc: 0.8878\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1988 - acc: 0.8943\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2039 - acc: 0.8894\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2117 - acc: 0.8819\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2048 - acc: 0.8886\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2090 - acc: 0.8846\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2041 - acc: 0.8893\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2129 - acc: 0.8807\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2042 - acc: 0.8892\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2064 - acc: 0.8871\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2131 - acc: 0.8806\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2098 - acc: 0.8837\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2018 - acc: 0.8915\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2062 - acc: 0.8872\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2108 - acc: 0.8828\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2068 - acc: 0.8867\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2081 - acc: 0.8854\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1956 - acc: 0.8975\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2123 - acc: 0.8814\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2071 - acc: 0.8864\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2094 - acc: 0.8842\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2052 - acc: 0.8882\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.2065 - acc: 0.8869\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2031 - acc: 0.8903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1999 - acc: 0.8933\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2042 - acc: 0.8892\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2047 - acc: 0.8887\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2067 - acc: 0.8868\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2078 - acc: 0.8857\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2079 - acc: 0.8856\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2051 - acc: 0.8883\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2087 - acc: 0.8849\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2091 - acc: 0.8844\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2079 - acc: 0.8856\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2082 - acc: 0.8853\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2074 - acc: 0.8861\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.2098 - acc: 0.8837\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.2071 - acc: 0.8864\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.2027 - acc: 0.8907\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1976 - acc: 0.8956\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.2000 - acc: 0.8932\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.2027 - acc: 0.8906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 318us/step - loss: 0.5901 - acc: 0.7960\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.3320 - acc: 0.8567\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1928 - acc: 0.9079\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1487 - acc: 0.9107\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1327 - acc: 0.9147\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1328 - acc: 0.9090\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1302 - acc: 0.9149\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1324 - acc: 0.9099\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1248 - acc: 0.9158\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1359 - acc: 0.9053\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1301 - acc: 0.9119\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1321 - acc: 0.9071\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1278 - acc: 0.9171\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1325 - acc: 0.9097\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1293 - acc: 0.9079\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1258 - acc: 0.9110\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1276 - acc: 0.9164\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1302 - acc: 0.9129\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1288 - acc: 0.9092\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1311 - acc: 0.9115\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1261 - acc: 0.9150\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1301 - acc: 0.9119\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1333 - acc: 0.9075\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1260 - acc: 0.9078\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1330 - acc: 0.9054\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1283 - acc: 0.9096\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1267 - acc: 0.9124\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1280 - acc: 0.9133\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1285 - acc: 0.9074\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1328 - acc: 0.9135\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1296 - acc: 0.9119\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1323 - acc: 0.9090\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1273 - acc: 0.9099\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1279 - acc: 0.9121\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1206 - acc: 0.9172\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1277 - acc: 0.9096\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1280 - acc: 0.9101\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1365 - acc: 0.9081\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1257 - acc: 0.9128\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1322 - acc: 0.9069\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1292 - acc: 0.9112\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1224 - acc: 0.9151\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1308 - acc: 0.9119\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1279 - acc: 0.9106\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1292 - acc: 0.9093\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1279 - acc: 0.9057: 0s - loss: 0.1274 - acc: 0.9\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1256 - acc: 0.9156\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1276 - acc: 0.9082\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1255 - acc: 0.9167\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1287 - acc: 0.9036\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1283 - acc: 0.9056\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1325 - acc: 0.9079\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1267 - acc: 0.9117\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1270 - acc: 0.9143\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1353 - acc: 0.9090\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1315 - acc: 0.9053\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1239 - acc: 0.9124\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1311 - acc: 0.9144\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1303 - acc: 0.9104\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1285 - acc: 0.9078\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1202 - acc: 0.9182\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1306 - acc: 0.9085\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1270 - acc: 0.9129\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1274 - acc: 0.9167\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1293 - acc: 0.9112\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1255 - acc: 0.9140\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1279 - acc: 0.9157\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1369 - acc: 0.9031\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1202 - acc: 0.9204\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1332 - acc: 0.9143\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1290 - acc: 0.9083\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1306 - acc: 0.9104\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1291 - acc: 0.9079\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1312 - acc: 0.9100\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1227 - acc: 0.9179\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1215 - acc: 0.9164\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1321 - acc: 0.9097\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1259 - acc: 0.9133\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1284 - acc: 0.9099\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1353 - acc: 0.9065\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1348 - acc: 0.9060\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1268 - acc: 0.9125\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1321 - acc: 0.9079\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1322 - acc: 0.9067\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1291 - acc: 0.9126\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1230 - acc: 0.9190\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1328 - acc: 0.9087\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 78us/step - loss: 0.1296 - acc: 0.9081\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1313 - acc: 0.9081\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1309 - acc: 0.9078\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1299 - acc: 0.9094\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1308 - acc: 0.9093\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1290 - acc: 0.9124\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1335 - acc: 0.9061\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1260 - acc: 0.9147\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1288 - acc: 0.9125\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1236 - acc: 0.9169\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1313 - acc: 0.9154\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1311 - acc: 0.9093\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1280 - acc: 0.9112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 3s 358us/step - loss: 0.6239 - acc: 0.7928\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.4582 - acc: 0.7940\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.3203 - acc: 0.7940\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2450 - acc: 0.7940\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2287 - acc: 0.8087\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2165 - acc: 0.8883\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2132 - acc: 0.8861\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2052 - acc: 0.8922\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2030 - acc: 0.8928\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2017 - acc: 0.8932\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2038 - acc: 0.8907\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2106 - acc: 0.8839\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2103 - acc: 0.8842\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2037 - acc: 0.8906\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2047 - acc: 0.8896\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2064 - acc: 0.8879\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2037 - acc: 0.8906\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.2061 - acc: 0.8882\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 131us/step - loss: 0.2010 - acc: 0.8931\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 139us/step - loss: 0.2064 - acc: 0.8879\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 132us/step - loss: 0.2088 - acc: 0.8857\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 127us/step - loss: 0.2150 - acc: 0.8797\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.2069 - acc: 0.8875\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.2082 - acc: 0.8862\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2030 - acc: 0.8912\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2074 - acc: 0.8869\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2058 - acc: 0.8885\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2096 - acc: 0.8849\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2011 - acc: 0.8931\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2144 - acc: 0.8803\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1987 - acc: 0.8953\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2067 - acc: 0.8876\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2052 - acc: 0.8890\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2045 - acc: 0.8897\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2025 - acc: 0.8917\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2086 - acc: 0.8858\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2070 - acc: 0.8874\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2058 - acc: 0.8885\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2009 - acc: 0.8932\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2076 - acc: 0.8868\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1944 - acc: 0.8993\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2034 - acc: 0.8908\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2103 - acc: 0.8843\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2076 - acc: 0.8868\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2025 - acc: 0.8917\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2075 - acc: 0.8869\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2012 - acc: 0.8929\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1976 - acc: 0.8962\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2100 - acc: 0.8846\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2067 - acc: 0.8876\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 91us/step - loss: 0.1989 - acc: 0.8950\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2081 - acc: 0.8864\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2156 - acc: 0.8792\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2044 - acc: 0.8899\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2025 - acc: 0.8917\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.2069 - acc: 0.8875\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1973 - acc: 0.8965\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2031 - acc: 0.8911\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2019 - acc: 0.8922\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2045 - acc: 0.8897\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1956 - acc: 0.8981\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1993 - acc: 0.8946\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1993 - acc: 0.8946\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2041 - acc: 0.8901\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2026 - acc: 0.8915\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2049 - acc: 0.8894\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2109 - acc: 0.8837\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2130 - acc: 0.8817\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1992 - acc: 0.8949\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1988 - acc: 0.8951\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2008 - acc: 0.8932\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2026 - acc: 0.8915\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.2075 - acc: 0.8869\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2088 - acc: 0.8857\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1979 - acc: 0.8960\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2075 - acc: 0.8869\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2025 - acc: 0.8917\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2039 - acc: 0.8903\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2056 - acc: 0.8887\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2019 - acc: 0.8922\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2026 - acc: 0.8915\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.2069 - acc: 0.8875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2079 - acc: 0.8865\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2050 - acc: 0.8893\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2051 - acc: 0.8892\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1995 - acc: 0.8944\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2022 - acc: 0.8919\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.2036 - acc: 0.8906\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2020 - acc: 0.8921\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.2045 - acc: 0.8897\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1983 - acc: 0.8956\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.2068 - acc: 0.8876\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.2008 - acc: 0.8932\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1992 - acc: 0.8947\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1972 - acc: 0.8965\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2029 - acc: 0.8912\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2147 - acc: 0.8803\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2054 - acc: 0.8889\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1973 - acc: 0.8965\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.2141 - acc: 0.8807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 3s 363us/step - loss: 0.5907 - acc: 0.8256\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.3045 - acc: 0.9303\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1633 - acc: 0.9435\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1440 - acc: 0.9399\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1388 - acc: 0.9407\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1467 - acc: 0.9382\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1381 - acc: 0.9418\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1467 - acc: 0.9389\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1381 - acc: 0.9393\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1476 - acc: 0.9350\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1320 - acc: 0.9437\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1388 - acc: 0.9379\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1478 - acc: 0.9400\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1347 - acc: 0.9415\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1366 - acc: 0.9428\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1413 - acc: 0.9392\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1480 - acc: 0.9358\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1389 - acc: 0.9426\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1394 - acc: 0.9417\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1443 - acc: 0.9378\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1389 - acc: 0.9399\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1375 - acc: 0.9406\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1410 - acc: 0.9407\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1432 - acc: 0.9381\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1322 - acc: 0.9433\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1441 - acc: 0.9386\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1489 - acc: 0.9365\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1408 - acc: 0.9379\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1385 - acc: 0.9421\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1370 - acc: 0.9404\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1413 - acc: 0.9379\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1464 - acc: 0.9379\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1388 - acc: 0.9408\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1380 - acc: 0.9397\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1393 - acc: 0.9412\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1357 - acc: 0.9410\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1438 - acc: 0.9372\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1423 - acc: 0.9406\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1418 - acc: 0.9404\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1376 - acc: 0.9403\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1398 - acc: 0.9396\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1364 - acc: 0.9408\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1394 - acc: 0.9392\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1411 - acc: 0.9399\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1387 - acc: 0.9387\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1439 - acc: 0.9400\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1453 - acc: 0.9367\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1427 - acc: 0.9386\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1483 - acc: 0.9356\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1301 - acc: 0.9461\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1453 - acc: 0.9381\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1345 - acc: 0.9431\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1386 - acc: 0.9389\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1418 - acc: 0.9378\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1355 - acc: 0.9419\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1361 - acc: 0.9394\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1413 - acc: 0.9382\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1356 - acc: 0.9421\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1355 - acc: 0.9425\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1389 - acc: 0.9422\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1455 - acc: 0.9386\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1383 - acc: 0.9439\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1401 - acc: 0.9435\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1278 - acc: 0.9450\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1402 - acc: 0.9389\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1339 - acc: 0.9406\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1409 - acc: 0.9408\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1343 - acc: 0.9424\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1378 - acc: 0.9424\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1381 - acc: 0.9401\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1377 - acc: 0.9426\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1430 - acc: 0.9378\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1379 - acc: 0.9393\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1392 - acc: 0.9426\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1384 - acc: 0.9411\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1452 - acc: 0.9404\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1421 - acc: 0.9357\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1415 - acc: 0.9357\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1448 - acc: 0.9393\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1462 - acc: 0.9376\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1403 - acc: 0.9372\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1353 - acc: 0.9387\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1404 - acc: 0.9387\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1385 - acc: 0.9407\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1415 - acc: 0.9385\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1356 - acc: 0.9412\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1350 - acc: 0.9419\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 79us/step - loss: 0.1401 - acc: 0.9390\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1372 - acc: 0.9404\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1412 - acc: 0.9385\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1378 - acc: 0.9399\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1445 - acc: 0.9337\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1433 - acc: 0.9387\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1382 - acc: 0.9415\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1416 - acc: 0.9404\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1327 - acc: 0.9429\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1360 - acc: 0.9424\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1362 - acc: 0.9437\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1388 - acc: 0.9417\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1377 - acc: 0.9422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 3s 367us/step - loss: 0.5407 - acc: 0.7967\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.2747 - acc: 0.8454\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.1733 - acc: 0.8749\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1290 - acc: 0.9494\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1167 - acc: 0.9522\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.1098 - acc: 0.9546\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1170 - acc: 0.9494\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1109 - acc: 0.9533\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1112 - acc: 0.9518\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1130 - acc: 0.9506\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1162 - acc: 0.9487\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1180 - acc: 0.9472\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1154 - acc: 0.9494\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1152 - acc: 0.9500\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1093 - acc: 0.9529\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1081 - acc: 0.9536\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1101 - acc: 0.9526\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1078 - acc: 0.9539\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1166 - acc: 0.9465\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1186 - acc: 0.9461\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1037 - acc: 0.9571\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1134 - acc: 0.9501\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1116 - acc: 0.9515\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1128 - acc: 0.9499\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1124 - acc: 0.9500\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1106 - acc: 0.9511\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1087 - acc: 0.9531\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1112 - acc: 0.9500\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1104 - acc: 0.9517\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1104 - acc: 0.9524\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1135 - acc: 0.9496\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1129 - acc: 0.9497\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1104 - acc: 0.9519: 0s - loss: 0.1091 - acc: 0.952\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1161 - acc: 0.9469\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1119 - acc: 0.9508\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1083 - acc: 0.9529\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1113 - acc: 0.9514\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1049 - acc: 0.9546\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1098 - acc: 0.9521\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1106 - acc: 0.9512\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1109 - acc: 0.9510\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1076 - acc: 0.9526\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1191 - acc: 0.9456\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1087 - acc: 0.9531\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1162 - acc: 0.9479\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1129 - acc: 0.9501\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1166 - acc: 0.9478\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1110 - acc: 0.9514\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1153 - acc: 0.9485\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1111 - acc: 0.9511\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1115 - acc: 0.9503\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1039 - acc: 0.9557\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1119 - acc: 0.9508\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1073 - acc: 0.9547\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1149 - acc: 0.9487\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1064 - acc: 0.9544\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1070 - acc: 0.9539\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1151 - acc: 0.9490\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1096 - acc: 0.9517\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1116 - acc: 0.9511\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1103 - acc: 0.9525\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1194 - acc: 0.9451\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1161 - acc: 0.9481\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1130 - acc: 0.9500\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1163 - acc: 0.9467\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 105us/step - loss: 0.1084 - acc: 0.9524\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 114us/step - loss: 0.1188 - acc: 0.9450\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1099 - acc: 0.9512\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.1148 - acc: 0.9483\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1160 - acc: 0.9482\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1101 - acc: 0.9508\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1162 - acc: 0.9489\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1139 - acc: 0.9486\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1072 - acc: 0.9529\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1124 - acc: 0.9501: 0s - loss: 0.1137 - acc: 0.\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1163 - acc: 0.9475\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1143 - acc: 0.9489\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1115 - acc: 0.9508\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1119 - acc: 0.9504\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1104 - acc: 0.9512\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1070 - acc: 0.9537\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1124 - acc: 0.9503\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1180 - acc: 0.9453\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1210 - acc: 0.9439\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1056 - acc: 0.9550\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1044 - acc: 0.9557\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1079 - acc: 0.9539\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1145 - acc: 0.9482\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1146 - acc: 0.9489\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1128 - acc: 0.9501\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1136 - acc: 0.9486\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1102 - acc: 0.9522\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1118 - acc: 0.9504\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1083 - acc: 0.9531\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1102 - acc: 0.9519\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1152 - acc: 0.9482\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1152 - acc: 0.9481\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1139 - acc: 0.9494\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1129 - acc: 0.9496\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1072 - acc: 0.9540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 2s 338us/step - loss: 0.5629 - acc: 0.7969\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.2767 - acc: 0.8590\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1870 - acc: 0.8694\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1557 - acc: 0.9157\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1458 - acc: 0.9240\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1437 - acc: 0.9194\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.1405 - acc: 0.9197\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1440 - acc: 0.9165\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.1382 - acc: 0.9225\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1388 - acc: 0.9218\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1338 - acc: 0.9229\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1405 - acc: 0.9143\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1364 - acc: 0.9203\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1393 - acc: 0.9178\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1292 - acc: 0.9240\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1398 - acc: 0.9156\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1405 - acc: 0.9144\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1331 - acc: 0.9224\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1317 - acc: 0.9239\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1295 - acc: 0.9251\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1392 - acc: 0.9181\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1345 - acc: 0.9203\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1353 - acc: 0.9211\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1343 - acc: 0.9210\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1351 - acc: 0.9192\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1309 - acc: 0.9217\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1336 - acc: 0.9233\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1319 - acc: 0.9233\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1360 - acc: 0.9217\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1386 - acc: 0.9182\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1367 - acc: 0.9192\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1308 - acc: 0.9260\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1327 - acc: 0.9226\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1262 - acc: 0.9314\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1368 - acc: 0.9212\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1340 - acc: 0.9221\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1367 - acc: 0.9192\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1330 - acc: 0.9228\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1334 - acc: 0.9243\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1327 - acc: 0.9206\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1336 - acc: 0.9235\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1324 - acc: 0.9221\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1357 - acc: 0.9199\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1278 - acc: 0.9299\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1315 - acc: 0.9228\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1315 - acc: 0.9231\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1349 - acc: 0.9201\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1373 - acc: 0.9161\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1303 - acc: 0.9269\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1332 - acc: 0.9224\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1272 - acc: 0.9251\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1291 - acc: 0.9256\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1291 - acc: 0.9229\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1352 - acc: 0.9208\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1330 - acc: 0.9189\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1347 - acc: 0.9218\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1418 - acc: 0.9172\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1360 - acc: 0.9179\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1362 - acc: 0.9172\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1370 - acc: 0.9175\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1372 - acc: 0.9192\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1317 - acc: 0.9229\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1329 - acc: 0.9242\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1341 - acc: 0.9224\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1345 - acc: 0.9221\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1349 - acc: 0.9190\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1354 - acc: 0.9199\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1309 - acc: 0.9249\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1312 - acc: 0.9219\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1329 - acc: 0.9221\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1343 - acc: 0.9194\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1278 - acc: 0.9267\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1367 - acc: 0.9178\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1316 - acc: 0.9217\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1355 - acc: 0.9208\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1452 - acc: 0.9121\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1398 - acc: 0.9162\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1324 - acc: 0.9237\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1371 - acc: 0.9176\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1404 - acc: 0.9169\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.1313 - acc: 0.9247\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1353 - acc: 0.9185\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1354 - acc: 0.9214\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1370 - acc: 0.9165\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1358 - acc: 0.9218\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 1s 80us/step - loss: 0.1316 - acc: 0.9208\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1368 - acc: 0.9192\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1351 - acc: 0.9212\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1354 - acc: 0.9169\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 1s 82us/step - loss: 0.1355 - acc: 0.9224\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1349 - acc: 0.9215\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 1s 81us/step - loss: 0.1340 - acc: 0.9208\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1405 - acc: 0.9169\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 1s 159us/step - loss: 0.1341 - acc: 0.9194\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 1s 149us/step - loss: 0.1352 - acc: 0.9207\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 1s 165us/step - loss: 0.1300 - acc: 0.9237\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 1s 97us/step - loss: 0.1274 - acc: 0.9289\n",
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 1s 98us/step - loss: 0.1335 - acc: 0.9212\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 1s 86us/step - loss: 0.1369 - acc: 0.9193\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1344 - acc: 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=14, units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\97798\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 3s 414us/step - loss: 0.5949 - acc: 0.7982\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.3765 - acc: 0.8312\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.2630 - acc: 0.8504\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.2188 - acc: 0.8681: 0s - loss: 0.2227 - acc\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.2132 - acc: 0.8685\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.2086 - acc: 0.8658\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.2015 - acc: 0.8692\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1920 - acc: 0.8643\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1850 - acc: 0.8647\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1826 - acc: 0.8676\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1762 - acc: 0.8775\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1770 - acc: 0.8897\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1739 - acc: 0.8953\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1709 - acc: 0.8965\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 1s 83us/step - loss: 0.1737 - acc: 0.8917\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1711 - acc: 0.8953\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1801 - acc: 0.8897\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 1s 84us/step - loss: 0.1713 - acc: 0.8951\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1752 - acc: 0.8947\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 1s 90us/step - loss: 0.1799 - acc: 0.8885\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.1760 - acc: 0.8931\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1755 - acc: 0.8928\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1765 - acc: 0.8894\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 1s 85us/step - loss: 0.1783 - acc: 0.8914\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 1s 88us/step - loss: 0.1717 - acc: 0.8968\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 1s 89us/step - loss: 0.1683 - acc: 0.8986\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 1s 87us/step - loss: 0.1709 - acc: 0.8976\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 1s 92us/step - loss: 0.1735 - acc: 0.8956\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 1s 103us/step - loss: 0.1763 - acc: 0.8901\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 1s 99us/step - loss: 0.1801 - acc: 0.8862\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1846 - acc: 0.8832\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 1s 93us/step - loss: 0.1792 - acc: 0.8892\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 1s 94us/step - loss: 0.1746 - acc: 0.8931\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1791 - acc: 0.8875\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1721 - acc: 0.8951\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1761 - acc: 0.8914\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 1s 96us/step - loss: 0.1743 - acc: 0.8954\n",
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 1s 101us/step - loss: 0.1760 - acc: 0.8942\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 1s 95us/step - loss: 0.1767 - acc: 0.8904\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 1s 107us/step - loss: 0.1788 - acc: 0.8885\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 1s 100us/step - loss: 0.1704 - acc: 0.8961\n",
      "Epoch 42/100\n",
      " 825/7200 [==>...........................] - ETA: 0s - loss: 0.1751 - acc: 0.8861"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-62f4d946b11d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m                            \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                            cv = 10)\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    720\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    709\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 711\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    823\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def build_classifier(optimizers):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 6, init = \"uniform\", activation = 'relu', input_dim = 14))\n",
    "    classifier.add(Dropout(rate = 0.5))\n",
    "    classifier.add(Dense(output_dim = 6, init = \"uniform\", activation = \"relu\"))\n",
    "    classifier.add(Dropout(rate = 0.5))\n",
    "    classifier.add(Dense(output_dim = 1, init = \"uniform\", activation = \"sigmoid\"))\n",
    "    classifier.compile(optimizer = optimizers, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [25, 32],\n",
    "              'epochs': [100, 500],\n",
    "              'optimizers':[\"adam\", \"rmsprop\"]}\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "grid_search = grid_search.fit(X_train, Y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
